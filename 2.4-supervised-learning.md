# 2.4 Supervised Learning

## **0.1. Linear ? Non-Linear ?** <a id="94ec"></a>

### 중첩의 원리\(Superposition Principle\) <a id="2bce"></a>

선형 [미분 방정식](https://ko.wikipedia.org/wiki/%EB%AF%B8%EB%B6%84_%EB%B0%A9%EC%A0%95%EC%8B%9D)의 해의 [선형 결합](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%EA%B2%B0%ED%95%A9)이 선형 미분 방정식의 또다른 해가 된다.

미분 방정식 : 미지의 [함수](https://namu.wiki/w/%ED%95%A8%EC%88%98)와 그 함수의 [도함수](https://namu.wiki/w/%EB%8F%84%ED%95%A8%EC%88%98)들로 이루어져 있는 [방정식](https://namu.wiki/w/%EB%B0%A9%EC%A0%95%EC%8B%9D)  
선형 결합 : 벡터들을 스칼라 곱과 벡터의 덧셈을 조합하여 새로운 벡터를 얻는 연산. ex\) x\[3 1\]+y\[−1 1\]=\[−2 2\]

**linear function**

```text
f(x) = ax + b
x1 + x2 = x3y1 = f(x1), y2 = f(x2)라면
y3 = f(x1 + x2) = y1 + y2
```

_**non-linear function**_

```text
f(x) = ax²
x1 + x2 = x3
y1 =f(x1), y2 = f(x2) 일때
y3 = f(x1 + x2) = y1 + y2 가 성립하지 않는다
```

어떤 함수가 Linear 라면, 한 함수값을 여러 개의 다른 함수값으로부터 쉽게 유추할 수 있다.

## 0.2. Regression ? <a id="279e"></a>

**종속변수 y를 다른 변수들 x1,x2, …, xn 으로 설명하는 자료분석 방법**이다.  
여기서 종속변수는 설명이 되는 변수로 반응변수라고도 한다. 그리고 설명을 위해 쓰이는 변수들을 설명변수 또는 독립변수라고 한다.

### “Regression” <a id="da6b"></a>

```text
회귀분석(regression analysis)은 ‘평균으로의 회귀’(regression to the mean / regression towards mediocrity) 현상을 생물학자 프랜시스 골턴에 의해 성립된 것으로 알려져 있다. ‘평균으로의 회귀’는 어떤 현상을 계량화하여 측정했을 때 쉽게 상상할 수 없는 극단적인 값이 검출되었다고 하더라도, 그 다음에 새로 측정을 했을 때에는 이전에 측정했던 자료들의 평균에 더 가까워지는 경향성을 이야기한다.현대에 와서는 회귀(regress), 즉 평균으로 돌아간다는 의미는 거의 사라졌다. 요즘에는 독립변수와 종속변수를 설정하고 이들의 관계를 통계적으로 살펴보는 대부분의 방법론을 다 회귀분석이라고 부르기도 한다.
```

## 0.3. Logistic ? <a id="30b2"></a>

= 기호 논리

```text
…
Leibniz는 진리를 추구하는 철학자들은 늘 논쟁을 하는 반면 계산을 하는 수학자들은 늘 의견일치를 보는 것에 착안해 논리 문제를 수학적인 방법으로 해결하려고 했다. 
…
이 모든 계산법의 특징은 계산에 사용되는 항목을 수나 문자 등 기호를 표시하며 그 기호들의 상호 기능을 역시 기호로 표시해 기능 법칙을 적용하는 데 있다
…
논리적 계산을 “기호 논리”라고 하는 것은 논리 추리에 필요한 명제(命題, proposition)를 예를 들면 p, q, p’, q’ 등 기호로 표시하고, 두 명제의 기능 관계, 즉 함수 관계(function)를, 예를 들면 →(내포하고 있다), &(과), v(혹), ~(부정) 등 기호로 표시하기 때문이다.
```

..?.?

## 0.4. Bayes’ theorem ? <a id="a02e"></a>

```text
P(A)와 P(B)는 독립
P(A) = A가 일어날 확률
P(B) =  B가 일어날 확률
P(B|A) = A가 일어나고나서 B가 일어날 확률
P(A|B) = B가 일어나고나서 A가 일어날 확률
```

이라고 하면, 아래 식이 성립한다

```text
P(A|B)=P(B|A)P(A)P(B)
```

## 0.5. maximum likelihood method ? <a id="3203"></a>

```text
어떤 확률변수에서 표집한 값들을 토대로 그 확률변수의 모수를 구하는 방법. 표본에서 모수를 구하는 법. 즉, 어떤 모수가 주어졌을 때, 원하는 값들이 나올 가능도를 최대로 만드는 모수를 선택하는 방법.
```

확률변수 집합 D = \(X1,X2, …, Xn\)가 있고 그것의 확률질량함수를 f 라고 할 때  
X1, X2, …, Xn이 각각 독립이고 같은 확률 분포를 가지고 있으면 가능도 L은![](https://miro.medium.com/max/60/1*ElcXcCrDdWpnPu2tlzD5Fg.png?q=20)

![](https://miro.medium.com/max/6344/1*ElcXcCrDdWpnPu2tlzD5Fg.png)

로 나타낼 수 있다.

동전 던지기 예시 : [https://wikidocs.net/7679](https://wikidocs.net/7679)

## 1. Linear Regression Analysis <a id="8a56"></a>

![](https://miro.medium.com/max/4428/1*Wga-vYCHWXNQpNjqlV8X6w.png)

```text
y= wTx + a + ε
```

여기서 wx + a 는 이론적으로 도출된 값이고, ε는 오차항이다.  
선형 회귀 분석의 목표는 ε를 최소화 하는 것으로, ε에는 일반적으로 다음과 같은 가정을 붙인다:

> \(1\) _**ε**_**은 정규분포에 따른다**. 특정의 값 _x¡_에 대해서 여러 번 _y¡_를 [측정](https://terms.naver.com/entry.nhn?docId=729752&ref=y)하여 _ε¡_의 측정값을 많이 얻을 수 있다면 그것은 정규 분포에 가까운 형태로 [분산](https://terms.naver.com/entry.nhn?docId=727543&ref=y)되어 있다.  
> \(2\) _ε_의 기댓값은 0이다. 특정의 값 _x¡_ 대해서 여러 번 _y¡_를 측정하여 _ε¡_의 측정값을 많이 얻을 수 있다면 그 평균은 0이 된다.  
> \(3\) _ε_의 분산은 _x_의 값에 의해 달라지지 않는다. 바꾸어 말하면 우연의 동작용법은 _x_의 값에 의해 달라지지 않는다.  
> \(4\) 다른 관측 값의 _ε_은 각각 독립한다. 어떤 관측 대상에 특유의 사정에 의한 우연은 다른 관측 대상에 영향을 미치지 않는다.  
> \(5\) _x_의 값은 _ε_에, 즉 우연에 좌우되지 않는다. _ε_에 좌우되는 것은 _y_의 측정 값 뿐이다.

이러한 가정에서 오류 즉 _오차 제곱의 합 SSE\(w\)_을 유도한다.

또한 추정 오류를 최소화하는 것은 가능성을 최대화 하는 것이므로, SSE\(w\) 식에서 LL\(w\) 를 유도하고  
이걸 다시 w에 대한 식으로 푸는 과정을 거친다

## 2. Logistic Regression <a id="c8cd"></a>

![](https://miro.medium.com/max/4892/1*e7MM7G1Q-gHdcHUC-7RDPQ.png)

```text
독립 변수의 선형 결합을 이용해서 결과를 분류하기 위한 방법
```

분류 결과가 0과 1이면 Binary Logistic Regression, 그 이상이면 Multinomial Logistic Regression 이라고 한다.

### 2.1. Binary Logistic Regression <a id="73c6"></a>

이진 분류에서의 목표는 2개의 클래스를 구분하는 선분을 찾는 것이다.  
응답 변수 y 값이 클래스 c에 속할 확률을 Pr\( y = c \| x, k\) 라고 하면, 0에 속할 확률, 1에 속할 확률 각각은

```text
Pr( y = 0 | x), Pr( y = 1 | x)
Pr( y = 0 | x) + Pr( y = 1 | x) = 1
```

이라고 할 수 있다. 이때 선분의 기울기는

```text
Pr( y = 0 | x) / Pr( y = 1 | x)                               (1)
```

이다. 여기에 log를 취하면

```text
log ( Pr(y = 0 | x) / Pr( y = 1 | x))                         (2)
```

이다. 선형 결합에서 경계 선분은 wTx 로 표시되므로

```text
log ( Pr(y = 0 | x) / Pr( y = 1 | x)) = wTx                   (3)
```

라고 할 수 있다. \(1\)번식과 \(3\)번식을 이용해 P\(y = 1\|x\)와 P\(y = 0\|x\) 를 풀면

```text
Pr(y = 1|x) = 1 / (1 + exp(-wTx))                            (4)
Pr(y = 0|x) = exp(-wTx) / (1 + exp(-wTx))                    (5)
```

이 되고, 이때\(4\)를 g\(wTx\) 라 하면 \(5\) = 1 -g\(wTx\) 이 된다.  
여기서 g\(wTx\)는 로지스틱 함수로 클래스 확률을 계산하는데 이용된다.

\(+ 2번 식에서 로그를 취하는 이유는,  
로그를 취하지 않으면 로지스틱 함수는 1 / \(1-wTx\)가 되는데  
이 함수는 x = 0에 가까워질수록 y 값이 발산하는 형태가 되기 때문에 적절하지 않기 때문임\)

### 2.2. Multinomial Logistic Regression <a id="0689"></a>

\(유도 과정은 생략\)

클래스 c에 대해 Pr\( y = c \| x\)은

```text
Pr( y = c | x) = exp((wc)Tx) / Sum(j)(exp((wc)Tx))
```

로 정의되고, 이것을 벡터 vj에 대해 일반화하여 softmax 함수라고 정의한다.

```text
softmax(i, v) = exp(vi) / Sum(j)(exp(vj))
```

## 4. Naive Bayes Regression <a id="ea63"></a>

![](https://miro.medium.com/max/4000/1*v4iqS6BGh1grV0x2vZwSug.png)

```text
나이브 베이즈는 분류기를 만들 수 있는 간단한 기술로써 단일 알고리즘을 통한 훈련이 아닌 일반적인 원칙에 근거한 여러 알고리즘들을 이용하여 훈련된다. 
모든 나이브 베이즈 분류기는 공통적으로 모든 특성 값은 서로 독립임을 가정한다.
예를 들어, 특정 과일을 사과로 분류 가능하게 하는 특성들 (둥글다, 빨갛다, 지름 10cm)은 나이브 베이즈 분류기에서 특성들 사이에서 발생할 수 있는 연관성이 없음을 가정하고 각각의 특성들이 특정 과일이 사과일 확률에 독립적으로 기여 하는 것으로 간주한다.
```

**Naive: 순진한, 단순한. 특성 값이 서로 독립이라고 가정하기 때문에서 붙었다 함.**[나이브 베이즈 분류기이번 글에서는 문서 분류를 하기 위한 나이브 베이지안 분류기\(Naive Bayesian Classifier\)에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님과 역시 같은 대학의 정순영 교수님…ratsgo.github.io](https://ratsgo.github.io/machine%20learning/2017/05/18/naive/?source=post_page-----e58c4df11b04----------------------)

위 문서의 계산예시 1을 보면 이해가 빠르다.

## **References** <a id="ff05"></a>

[선형 함수\(linea function\)와 비선형 함수\(non-linear function\)의 차이!공과대학을 입학하고 수업을 들을 때, 가장 많이 듣는 말 중 하나는 선형\(Linearity\)과 비선형\(Non-linearity\)일 것이다. 선형이라는 것은 직선이 아닐 지라도 직선의 특징을 가지고 있다는 것이고…sdolnote.tistory.com](https://sdolnote.tistory.com/entry/LinearityNonlinearityFunction?source=post_page-----e58c4df11b04----------------------)

[중첩 원리중첩 원리\(重疊原理\)는 선형 미분 방정식의 해의 선형 결합이 선형 미분 방정식의 또다른 해가 된다는 원리다. 물리학에 등장하는 많은 미분 방정식 \( 파동 방정식, 라플라스 방정식, 슈뢰딩거 방정식, 맥스웰 방정식…ko.wikipedia.org](https://ko.wikipedia.org/wiki/%EC%A4%91%EC%B2%A9_%EC%9B%90%EB%A6%AC?source=post_page-----e58c4df11b04----------------------)

[회귀분석회귀분석은 종속변수 Y를 다른 변수들 X\_1, \ \cdots, \ X\_p로 설명하는 자료분석 방법이다. 여기서 종속변수는 설명이 되는 변수로 반응변수라고도 한다. 그리고 설명을 위해 쓰이는 변수들을 설명변수 또는…terms.naver.com](https://terms.naver.com/entry.nhn?docId=3338196&cid=47324&categoryId=47324&source=post_page-----e58c4df11b04----------------------)

[회귀분석회귀분석은 종속변수 Y를 다른 변수들 X\_1, \ \cdots, \ X\_p로 설명하는 자료분석 방법이다. 여기서 종속변수는 설명이 되는 변수로 반응변수라고도 한다. 그리고 설명을 위해 쓰이는 변수들을 설명변수 또는…terms.naver.com](https://terms.naver.com/entry.nhn?docId=3338196&cid=47324&categoryId=47324&source=post_page-----e58c4df11b04----------------------)

[Logistic영\] \(← , "計算者"\) 기호 논리. 아리스토텔레스의 창시 이래로 지금까지 세기를 통해 사용한 논리를 형식논리\(Logica formalis\)라 하는데 이 논리학은 어디까지나 사실과 생각의 일치를 추구하는 진리…terms.naver.com](https://terms.naver.com/entry.nhn?docId=2365700&cid=50762&categoryId=51340&source=post_page-----e58c4df11b04----------------------)

[머신러닝에서의 확률 분포, 랜덤 변수 그리고 Maximum Likelihood머신 러닝 정의는, 관측된 Data\(=Training Sample\)로부터 Model을 설계하는 것이다. 확률적 개념이 들어간다면, 관측된 Data는 진짜 Data가 아니라 진짜 Data로부터 Random하게…taeoh-kim.github.io](https://taeoh-kim.github.io/blog/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%97%90%EC%84%9C%EC%9D%98-%ED%99%95%EB%A5%A0-%EB%B6%84%ED%8F%AC-%EB%9E%9C%EB%8D%A4-%EB%B3%80%EC%88%98-%EA%B7%B8%EB%A6%AC%EA%B3%A0-maximum-likelihood/?source=post_page-----e58c4df11b04----------------------)

[활성함수\(Activation\) 시그모이드\(Sigmoid\)함수 정의 \| 알기 쉬운 산업수학 \| 산업수학혁신센터Edit descriptionicim.nims.re.kr](https://icim.nims.re.kr/post/easyMath/64?source=post_page-----e58c4df11b04----------------------)

[위키독스온라인 책을 제작 공유하는 플랫폼 서비스wikidocs.net](https://wikidocs.net/22892?source=post_page-----e58c4df11b04----------------------)

[위키독스온라인 책을 제작 공유하는 플랫폼 서비스wikidocs.net](https://wikidocs.net/7679?source=post_page-----e58c4df11b04----------------------)

[나이브 베이즈 분류기이번 글에서는 문서 분류를 하기 위한 나이브 베이지안 분류기\(Naive Bayesian Classifier\)에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강필성 교수님과 역시 같은 대학의 정순영 교수님…ratsgo.github.io  
](https://ratsgo.github.io/machine%20learning/2017/05/18/naive/?source=post_page-----e58c4df11b04----------------------)

